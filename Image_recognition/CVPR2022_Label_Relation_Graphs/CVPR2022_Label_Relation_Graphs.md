
# [CVPR2022] Label Relation Graphs Enhanced Hierarchical Residual Network for Hierarchical Multi-Granularity Classification

论文地址：https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Label_Relation_Graphs_Enhanced_Hierarchical_Residual_Network_for_Hierarchical_Multi-Granularity_CVPR_2022_paper.pdf
代码地址：https://github.com/MonsterZhZh/HRN

## 本文动机
基于有监督式深度学习的图像识别任务中一个方面要求是构建整理大规模、高质量的标注数据，这就对图像质量和标注人员的背景知识有比较高的要求。例如，在细粒度分类任务中，标注人员需要依赖大量的领域知识去区分各种种类的鸟以及不同型号的舰船，如图 1 所示。
![图1](图1.png)  

在图 1 中，标注人员需要借助鸟类专家的知识才能辨认黑脚信天翁与黑背信天翁，拥有一般鸟类知识的人员或许会将这两种鸟类归类为信天翁，而缺乏鸟类知识的人员可能只会将这两种鸟类归类为鸟。类似地，标注人员需要借助军事舰船专家的知识才能有效区分尼米兹级航母与企业级航母，而缺乏相关背景知识的人员可能会将这两类舰船归类为航母。也就是说，同一张图片会被拥有不同背景知识的标注人员标注到不同层级粒度的类别上。

除了背景知识对标注产生的影响，诸如鸟类辨别中的关键区域被遮挡、图像分辨率较低、或者图像比较模糊等图像质量因素也会干扰标注人员对于图像目标属于层级多粒度标签中的哪一类的判断，如图 2 所示。

![图2](图2.png)  
但是，传统的图像识别数据集类别设定中，针对某个特定任务例如通用图像分类任务或者细粒度分类任务，类别标签往往只位于同一层级中，无法鲁棒地利用标注到不同层级上的图片，对标注的要求较高。为了降低图像质量以及背景知识等带来的对标注数据的高要求、充分利用具有不同层级粒度标签的样本，设计建模目标层级语义结构的层级多粒度识别算法对于提升深度神经网络的鲁棒性具有十分重要的作用。
## 方法
我们从三点观察出发构建我们的层级多粒度分类算法：（1）由于细粒度类别可以根据不同层次的抽象向上不停迭代归类形成树形类别结构，我们构建对应的标签关系树建模层级类别间的语义关系；（2） 基于标签关系树设计复合损失函数，使得具有不同层级粒度标注的样本在学习时可以传递层级间的知识；（3）现实世界中位于低层级的子类除了拥有自己的独特属性还会进一步继承来自父类的属性，我们首先为每个层级设置专有的特征提取层，根据主干网 络输出的特征提取各个层级相关的特征。然后我们参考深度残差网络中经典的残差连接 设计，实现为所有父类层级的特征以残差连接的方式融合到子类层级专有的特征中，进而用于当前层级类别分类的层级残差网络(HRN)。 

标签关系树：  
标签关系树 $G=\left(V, E_{h}, E_{e}\right)$ 由节点集合 $V=\left\{v_{1}, \ldots, v_{n}\right\}$ 、有向边集合 $E_{h} \subseteq V \times V$ 、以及无向边集 所有标签的个数。一条有向边 $\left(v_{i}, v_{j}\right) \in E_{h}$ 代表节点 $\left(v_{i}, v_{j}\right)$ 间具有父子关系，及类别 $\mathrm{i}$ 是类别 $\mathrm{j}$ 的 父类。一条无向边 $\left(v_{i}, v_{j}\right) \in E_{e}$ 代表节点 $v_{i}$ 与 $v_{j}$ 为互斥关系。层级中每个类别标签取值为二元值， 即 $v_{i} \in\{0,1\}$ ，代表目标是否具有这个类别标签。图中每条边限制了相连节点的取值：对于具有父 子关系边相连的两个节点 $\left(v_{i}, v_{j}\right) \in E_{h},\left(v_{i}, v_{j}\right)=(0,1)$ 的赋值是违法的（是拉布拉多却不是 狗) ; 对于具有互后关系边相连的两个节点 $\left(v_{i}, v_{j}\right) \in E_{e},\left(v_{i}, v_{j}\right)=(1,1)$ 的赋值是违法的（既是柯 基又是拉布拉多)。图中所有边约束了层级多标签中相邻类别节点的合法取值，对于层级中所有标 签的一个全局合法赋值为一个二元标签向量 $y \in\{0,1\}^{n}$ 。所有全局合法诋值向量的集合构成标签关 系树 $\mathrm{G}$ 拥有的合法赋值空间 $\boldsymbol{S}_{G} \subseteq\{0,1\}^{n}$ 。

## 实验结果
ShTechA MAE：63.2 效果OK。(但里面有将attention map做一些阈值处理来得到这个效果，因此在有监督方法里面再继续这个方向做下去的意义可能不大)。

## 其他
希望作者能给出Attention map的ground truth是如何生成的说明。或者我理解错了，AME根本不需要ground truth。
